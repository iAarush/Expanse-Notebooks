{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST exercise with hypertuning\n",
    "**Goal: Introduction to Keras Tuner object**\n",
    "\n",
    "**Exercise:**\n",
    "    \n",
    "1. Review the steps of the code in this notebook\n",
    "2. Look for the build_model and build_model_hp functions \n",
    "3. run the notebook, review the summary of hypertuning results\n",
    "4. change the build_model functions and add one or two more parameters \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ----------- IMPORT STATEMENTS ---------------\n",
    "import numpy as np\n",
    "np.random.seed(1)  # for reproducibility\n",
    " \n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import datetime, os\n",
    "\n",
    "import keras_tuner as kt    #<<----- NEW import\n",
    "#---------------------------------------------\n",
    "print('import done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape: (1000, 28, 28, 1)\n",
      "X test shape: (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "#Load MNIST data from Keras datasets\n",
    "(X_train, Y_train), (X_test, Y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "X_train=X_train[0:1000,]  #only need smaller subset to get good results\n",
    "Y_train=Y_train[0:1000,]\n",
    "\n",
    "# --------- Reshape input data, b/c Keras expects N-3D images (ie 4D matrix)\n",
    "X_train = X_train[:,:,:,np.newaxis]\n",
    "X_test  = X_test[:,:,:,np.newaxis]\n",
    "\n",
    "#Scale 0 to 1  - or should we not scale\n",
    "X_train = X_train/255.0\n",
    "X_test  = X_test/255.0\n",
    "\n",
    "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
    "Y_train = keras.utils.to_categorical(Y_train, 10)\n",
    "Y_test  = keras.utils.to_categorical(Y_test,  10)\n",
    "\n",
    "# ------------- End loading and preparing data --------------\n",
    "print('X train shape:', X_train.shape) \n",
    "print('X test shape:', X_test.shape) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notice here is a new function for the hypertuner that wraps around the build-model function\n",
    "\n",
    "'hp' is an argument is this function\n",
    "\n",
    "hp is a hyperparameter tuner object\n",
    "\n",
    "See https://keras.io/keras_tuner/\n",
    "\n",
    "After running through the notebook, add a new parameter \n",
    "\n",
    "For example, add a set of choices for either 'relu' or 'elu' activation\n",
    "\n",
    "For details see here\n",
    "https://keras.io/api/keras_tuner/hyperparameters/#choice-method\n",
    "and here\n",
    "https://keras.io/api/layers/activations/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_hp(hp): \n",
    "  hp_numfilters    = hp.Int('hpnumfilters',min_value=8,max_value=32,step=4)\n",
    "  #your variable name         ^^^ the parameter name in the hp object\n",
    "\n",
    "  # For Step4  -------- Add code here (and below) --------------------\n",
    "  #  add a new parameter object; for example\n",
    "  hp_Activation    = hp.Choice('hpActivation', values=[___,___])  #<<<<----------- fill in code\n",
    "    \n",
    "  return build_model(hp_numfilters,______)   #<<---- dont forget to pass the new choices to build_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------Set up Model ---------------------\n",
    "def build_model(numfilters,__________):   #<<------if you add parameters to search, add them to the argument \n",
    "                                      #            list and change code to use those arguments\n",
    "    mymodel = keras.models.Sequential()\n",
    "    mymodel.add(keras.layers.Convolution2D(numfilters, \n",
    "                                       (3, 3),\n",
    "                                       strides=1,  \n",
    "                                       data_format=\"channels_last\",\n",
    "                                       activation=___________, #<<<< ---- add code\n",
    "                                       input_shape=(28,28,1))) \n",
    "    mymodel.add(keras.layers.Convolution2D(numfilters, \n",
    "                                       (3, 3),\n",
    "                                       strides=1,  \n",
    "                                       data_format=\"channels_last\",\n",
    "                                       activation=___________))\n",
    "    mymodel.add(keras.layers.MaxPooling2D(pool_size=(2,2),strides=2,data_format=\"channels_last\"))\n",
    "    mymodel.add(keras.layers.Flatten())            #reorganize 2DxFilters output into 1D\n",
    "  \n",
    "    #----------------Now add final classification layers\n",
    "    mymodel.add(keras.layers.Dense(32, activation=___________))   \n",
    "    mymodel.add(keras.layers.Dense(10, activation='softmax'))\n",
    "    print('assemble model done')\n",
    "    \n",
    "    # --------- Now configure model algorithm -----\n",
    "    mymodel.compile(loss='categorical_crossentropy',\n",
    "               optimizer=keras.optimizers.Adam(learning_rate=0.005),  \n",
    "               metrics=['accuracy'])\n",
    "\n",
    "    return mymodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up hypertuner object so that it will build model and run fit\n",
    "https://keras.io/keras_tuner/\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 13 Complete [00h 00m 13s]\n",
      "val_accuracy: 0.9181199908256531\n",
      "\n",
      "Best val_accuracy So Far: 0.9181199908256531\n",
      "Total elapsed time: 00h 02m 44s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Results summary\n",
      "Results in My_HP_trials/hyperbandtest\n",
      "Showing 5 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x1554f3252a60>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "hpnumfilters: 32\n",
      "hpActivation: relu\n",
      "tuner/epochs: 3\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 3\n",
      "tuner/round: 0\n",
      "Score: 0.9181199908256531\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "hpnumfilters: 28\n",
      "hpActivation: relu\n",
      "tuner/epochs: 3\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 3\n",
      "tuner/round: 0\n",
      "Score: 0.9134000062942504\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "hpnumfilters: 24\n",
      "hpActivation: relu\n",
      "tuner/epochs: 3\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 3\n",
      "tuner/round: 0\n",
      "Score: 0.9093600034713745\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "hpnumfilters: 20\n",
      "hpActivation: relu\n",
      "tuner/epochs: 3\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 3\n",
      "tuner/round: 0\n",
      "Score: 0.9075199961662292\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "hpnumfilters: 16\n",
      "hpActivation: relu\n",
      "tuner/epochs: 3\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 3\n",
      "tuner/round: 0\n",
      "Score: 0.9057200074195861\n"
     ]
    }
   ],
   "source": [
    "myES_function = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=5) #patience before stopping\n",
    "\n",
    "\n",
    "dirname        = 'My_HP_trials'   \n",
    "num_max_epochs = 60    #max to train 1 model, set this something higher than expected'\n",
    "\n",
    "tuner = kt.Hyperband(build_model_hp,\n",
    "                     objective  = 'val_accuracy',\n",
    "                     max_epochs = num_max_epochs,  \n",
    "                     factor     = 3,\n",
    "                     hyperband_iterations=10,  \n",
    "                     directory   =dirname, \n",
    "                     overwrite   =True,       #overwrite directory each run\n",
    "                     project_name='hyperbandtest',\n",
    "                     executions_per_trial=5,  #to try several initializations\n",
    "                     seed        =777)\n",
    "\n",
    "#this has same arguments as the model.fit function\n",
    "tunerhistory=tuner.search(X_train, Y_train, \n",
    "          validation_data=(X_test,Y_test),\n",
    "          batch_size=32, epochs=num_max_epochs, verbose=1,callbacks=[myES_function])\n",
    "        \n",
    "tuner.results_summary(5)\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info, best parameters: rank hpnumfilters activation\n",
      "                0 32 relu\n",
      "                1 28 relu\n",
      "                2 24 relu\n",
      "                3 20 relu\n",
      "                4 16 relu\n"
     ]
    }
   ],
   "source": [
    "#print(\"best to worst\\n\")\n",
    "print(\"Info, best parameters: rank hpnumfilters activation\")\n",
    "for i in range(len(best_hps)):\n",
    "        print(\"               \",i,best_hps[i].get('hpnumfilters'),  \n",
    "                                best_hps[i].get('hpActivation') ) # <<<<----- add code here\n",
    "              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best trials 0012\n"
     ]
    }
   ],
   "source": [
    " for trial in tuner.oracle.get_best_trials(): #[0].trial_id\n",
    "        print('best trials',trial.trial_id)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bracket 0 num rounds 1\n",
      "bracket 1 num rounds 2\n",
      "bracket 2 num rounds 3\n",
      "bracket 3 num rounds 4\n"
     ]
    }
   ],
   "source": [
    "for i in range(tuner.oracle._get_num_brackets()):\n",
    "   print('bracket',i,'num rounds',tuner.oracle._get_num_rounds(i))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
