{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J_hy9iCXlaax"
   },
   "source": [
    "## Transfer Learning on Cats-Dogs Classification - Feature Extraction\n",
    "\n",
    "#### Features are extracted from a MobileNet-V2 model pre-trained on ImageNet data, then passed through a new classification head to classify cats vs. dogs.\n",
    "Adapted from https://www.tensorflow.org/tutorials/images/transfer_learning\n",
    "\n",
    "### HPC and Data Science Summer Institute\n",
    "Mai H. Nguyen, UC San Diego\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8NmDHijos0sW"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "from sklearn.metrics import classification_report \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gjRHT_7ds0sX",
    "outputId": "c8449f05-2186-4b04-cd0e-65d786ff5659"
   },
   "outputs": [],
   "source": [
    "print(\"Tensorflow version:\",tf.__version__)\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l5OAYvK0s0sX"
   },
   "outputs": [],
   "source": [
    "# Set logging level\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qd4JjV5Cs0sX"
   },
   "outputs": [],
   "source": [
    "# Set random generator seed\n",
    "seed = 1234\n",
    "\n",
    "# Set Python seed, NumPy seed, and TensorFlow seed\n",
    "tf.keras.utils.set_random_seed(seed)\n",
    "\n",
    "# Set numpy random generator\n",
    "# np.random.seed(seed)\n",
    "\n",
    "# Set python built-in random generator\n",
    "# random.seed(seed)\n",
    "\n",
    "# Set tf global random seed\n",
    "# tf.random.set_seed(seed)\n",
    "\n",
    "# Disable hash randomization by specifying the value 0.\n",
    "# os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "# Potential randomness from CUDNN\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "os.environ['TF_CUDNN_DETERMINISTIC']= '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jLToN9Hxs0sY"
   },
   "source": [
    "### Set image location and dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "from os.path import expanduser\n",
    "HOME = expanduser(\"~\")\n",
    "data_path = HOME + '/data/catsVsDogs'\n",
    "print (data_path)\n",
    "\n",
    "# Set data_path:  Data is in home directory, under 'data/catsVsDogs'\n",
    "# ==> YOUR CODE HERE\n",
    "print (data_path)\n",
    "\n",
    "# Location of images\n",
    "train_data_dir = data_path + '/train'\n",
    "val_data_dir   = data_path + '/val'\n",
    "test_data_dir  = data_path + '/test'\n",
    "\n",
    "print ('Train path:' + train_data_dir)\n",
    "print ('Validation path:' + val_data_dir)\n",
    "print ('Test path:' + test_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hLJc4yoPFkpw"
   },
   "outputs": [],
   "source": [
    "# Image dimensions:  224 x 224\n",
    "# ==> YOUR CODE HERE\n",
    "IMG_SIZE = (img_width,img_height)\n",
    "IMG_SHAPE = IMG_SIZE + (3,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6Ef4ZtXFkpw"
   },
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G3Q9FYv9Fkpx",
    "outputId": "4036af6a-b1ed-4364-f93d-5363491303ac"
   },
   "outputs": [],
   "source": [
    "# Set batch size to 16\n",
    "# ==> YOUR CODE HERE\n",
    "\n",
    "# Data augmentation setup\n",
    "#rescale = tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset=-1)\n",
    "rescale = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "train_datagen      = ImageDataGenerator(shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True, preprocessing_function = rescale)\n",
    "validation_datagen = ImageDataGenerator(preprocessing_function = rescale)\n",
    "test_datagen       = ImageDataGenerator(preprocessing_function = rescale)\n",
    "\n",
    "# Set up generator to read images found in subfolders of training data directory,\n",
    "# and indefinitely generate batches of image data (scaled).  This is for training data.\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir,target_size=IMG_SIZE,\n",
    "                                              batch_size = BATCH_SIZE, class_mode='binary', \n",
    "                                              shuffle = True, seed = seed)           \n",
    "\n",
    "# Set up generator to generate batched of validation data for model\n",
    "validation_generator = validation_datagen.flow_from_directory(val_data_dir,target_size=IMG_SIZE,\n",
    "                                                   batch_size = BATCH_SIZE,class_mode='binary',\n",
    "                                                   shuffle = False, seed = seed)\n",
    "# Set up generator to generate batched of test data for model\n",
    "# ==> YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eTd7WZk4Fkpx"
   },
   "source": [
    "### Load pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WPZn2T6pFkpy",
    "outputId": "8c6f3689-f51c-4b8c-996e-ddd4a2d438d9"
   },
   "outputs": [],
   "source": [
    "#Load pre-trained model's Imagenet weights not including the fully connected layers\n",
    "base_model = applications.MobileNetV2(include_top = False, weights = 'imagenet', input_shape=IMG_SHAPE)\n",
    "\n",
    "# Freeze all weights of pre-trained model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Needed to keep BatchNormalization layers in inference mode for pre-trained model. \n",
    "# See https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization \n",
    "base_model.training  = False\n",
    "\n",
    "print ('Base model loaded')\n",
    "\n",
    "# Uncomment to ook at pre-trained model's architecture\n",
    "# base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UYHq--aQFkpy"
   },
   "source": [
    "### Create top model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sWKyyJsRFkpz",
    "outputId": "8e734cb8-9ef7-44de-d199-6a89910aa1d4"
   },
   "outputs": [],
   "source": [
    "img_inputs = tf.keras.Input(shape=(img_width, img_height, 3))\n",
    "base_outputs = base_model(img_inputs)\n",
    "\n",
    "GlobalAveragePooler2D = GlobalAveragePooling2D()\n",
    "GlobalAveragePooler2D_outputs = GlobalAveragePooler2D(base_outputs)\n",
    "\n",
    "Dropper = Dropout(0.2)\n",
    "DroppedOut_outputs = Dropper(GlobalAveragePooler2D_outputs)\n",
    "\n",
    "DenseLayer = Dense(1, activation='sigmoid')\n",
    "outputs = DenseLayer(DroppedOut_outputs)\n",
    "\n",
    "model = tf.keras.Model(inputs=img_inputs, outputs=outputs)\n",
    "\n",
    "# Get model summary\n",
    "# ==> YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EN_OU2QLFkpz"
   },
   "source": [
    "### Train top model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kqoD6t2gFkp0",
    "outputId": "10d134fa-2c59-452b-bf88-7f2c17d1f40c"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.0001),\n",
    "              loss= losses.BinaryCrossentropy(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "OtSHoi2RFkp0",
    "outputId": "5236a4a8-646e-4e22-fb12-30c5d841cce0"
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "# Train top model for 5 epochs\n",
    "# ==> YOUR CODE HERE\n",
    "\n",
    "train_history = model.fit(train_generator,validation_data=validation_generator, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "3l_OqEh7Fkp1"
   },
   "outputs": [],
   "source": [
    "# Save weights from trained model\n",
    "# Use model.save()\n",
    "# ==> YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 227
    },
    "id": "QSRIsKk4Fkp2",
    "outputId": "a314d78d-de94-4670-f5df-85ac0b800f91"
   },
   "outputs": [],
   "source": [
    "# Plot train and validation history\n",
    "fig, axs = plt.subplots(1,2, figsize= (20,5))\n",
    "axs[0].plot(train_history.history['loss'])\n",
    "axs[0].plot(train_history.history['val_loss'])\n",
    "axs[0].set_title(\"Train, Val loss history\")\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "axs[0].legend([\"Train Loss\",\"Val Loss\"])\n",
    "\n",
    "axs[1].plot(train_history.history['accuracy'])\n",
    "axs[1].plot(train_history.history['val_accuracy'])\n",
    "axs[1].set_title(\"Train, Val Accuracy history\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].legend([\"Train Accuracy\",\"Val Accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ONG1hT4Fkp2"
   },
   "source": [
    "### Evaluation and Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3nOLqnu3Fkp2",
    "outputId": "d48e5627-a938-4349-b966-b8ede83995ec"
   },
   "outputs": [],
   "source": [
    "# Get train data accuracy\n",
    "_, train_accuracy = model.evaluate(train_generator)\n",
    "print(\"Train data accuracy:\", train_accuracy)\n",
    "\n",
    "# Get test data accuracy\n",
    "# ==> YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "U18CzlMmFkp3",
    "outputId": "4c4784b2-da7c-413a-8021-736f270cba4f"
   },
   "outputs": [],
   "source": [
    "# Get predicted value and the ground truth value of test data\n",
    "pred = (model.predict(test_generator) > 0.5).astype(\"int32\")\n",
    "true = test_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "GVRlc00IFkp3",
    "outputId": "513d9f2e-9182-4d83-d602-712b2b59f2bd"
   },
   "outputs": [],
   "source": [
    "# Get evaluation metrics for test data\n",
    "print(classification_report(y_true= true, y_pred = pred, target_names=['cats', 'dogs'], digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kanEZ6sIFkp3"
   },
   "source": [
    "### Perform inference on test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Kjjez9BCFkp4"
   },
   "outputs": [],
   "source": [
    "def image_loader(img_file):\n",
    "    img = load_img(img_file, target_size = (img_width, img_height))\n",
    "    imgplot = plt.imshow(img)\n",
    "    plt.show()\n",
    "    # img = img_to_array(img) / 255\n",
    "    img = (img_to_array(img)/127.5)-1.0\n",
    "    img = np.expand_dims(img, axis = 0) #model input is (1,width,height,channels)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "9e4n7HUPFkp4",
    "outputId": "585909df-6e00-4d45-9fe3-e39b0582c46f"
   },
   "outputs": [],
   "source": [
    "test_image = data_path + '/test/cats/cat.1070.jpg'\n",
    "img = image_loader(test_image)\n",
    "img_y_pred = model.predict(img) \n",
    "print(np.round(img_y_pred,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rJVNPssvFkp4"
   },
   "outputs": [],
   "source": [
    "test_image = data_path + '/test/dogs/dog.1233.jpg'\n",
    "img = image_loader(test_image)\n",
    "img_y_pred = model.predict(img) \n",
    "print(np.round(img_y_pred,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = data_path + '/test/cats/cat.1080.jpg'\n",
    "\n",
    "# Load the image\n",
    "# ==> YOUR CODE HERE\n",
    "\n",
    "img_y_pred = model.predict(img) \n",
    "print(np.round(img_y_pred,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = data_path + '/test/dogs/dog.1132.jpg'\n",
    "img = image_loader(test_image)\n",
    "\n",
    "# Get the model's prediction on image\n",
    "# ==> YOUR CODE HERE\n",
    "\n",
    "print(np.round(img_y_pred,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform inference on dog image 1311\n",
    "# ==> YOUR CODE HERE\n",
    "\n",
    "img = image_loader(test_image)\n",
    "img_y_pred = model.predict(img) \n",
    "print(np.round(img_y_pred,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "feature_extract_tf_soln_avg.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
