{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST exercise (handwritten printed digits recognition tutorial) ##\n",
    "**Goal: Introduction to Keras, convolution feature maps, and features**\n",
    "\n",
    "**Exercise:**\n",
    "    \n",
    "1. Review the steps of the code in this notebook\n",
    "2. Look for the model.Sequential statement \n",
    "   and fill in the blanks: <br>\n",
    "3. run the notebook, observe the images of filter weights and activations (at end)\n",
    "4. Try changing the filter size for the first convolution layer to something large (like 9x9 or 16x16)\n",
    "        How does that change the images of filter weights and activations?\n",
    "<br>\n",
    "Question to consider: for 10 digits what is min number of filters needed?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-02 00:38:48.683405: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9373] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-02 00:38:48.684547: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-02 00:38:48.862083: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1534] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-02 00:38:49.190819: I tensorflow/core/platform/cpu_feature_guard.cc:183] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ----------- IMPORT STATEMENTS ---------------\n",
    "import numpy as np\n",
    "np.random.seed(1)  # for reproducibility\n",
    " \n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import datetime, os\n",
    "\n",
    "\n",
    "#---------------------------------------------\n",
    "print('import done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 0s 0us/step\n",
      "X train shape: (1000, 28, 28, 1)\n",
      "X test shape: (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "#Load MNIST data from Keras datasets\n",
    "(X_train, Y_train), (X_test, Y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "X_train=X_train[0:1000,]  #only need smaller subset to get good results\n",
    "Y_train=Y_train[0:1000,]\n",
    "\n",
    "# --------- Reshape input data, b/c Keras expects N-3D images (ie 4D matrix)\n",
    "X_train = X_train[:,:,:,np.newaxis]\n",
    "X_test  = X_test[:,:,:,np.newaxis]\n",
    "\n",
    "#Scale 0 to 1  - or should we not scale\n",
    "X_train = X_train/255.0\n",
    "X_test  = X_test/255.0\n",
    "\n",
    "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
    "Y_train = keras.utils.to_categorical(Y_train, 10)\n",
    "Y_test  = keras.utils.to_categorical(Y_test,  10)\n",
    "\n",
    "# ------------- End loading and preparing data --------------\n",
    "print('X train shape:', X_train.shape) \n",
    "print('X test shape:', X_test.shape) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Fill in the blanks for the convolution parameters\n",
    "\n",
    "Follow the URL link to see the Keras api documentation for command format\n",
    "\n",
    "https://keras.io/api/layers/convolution_layers/convolution2d/\n",
    "\n",
    "\n",
    "Try for example, 32,16 or 8 filters\n",
    "Try 3x3 or 9x9 or 16x16 filter sizes\n",
    "\n",
    "NOTE that we are using a function to build the model, which will be useful later\n",
    "\n",
    "##  2 Change the optimizer to use Adam\n",
    "Notice that Keras parameters can sometimes be filled in with a string (like 'adam') or sometimes with function like keras.optimizers.Adam(learning_rate=0.01).\n",
    "See the example at this link:\n",
    "\n",
    "https://keras.io/api/optimizers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------Set up Model ---------------------\n",
    "def build_model(numfilters):   #<<<---- Hint, use this argument \n",
    "    mymodel = keras.models.Sequential()\n",
    "    mymodel.add(keras.layers.Convolution2D(_________,      #<<<< ------ 1\n",
    "                                       (___,___),\n",
    "                                       strides=1,  \n",
    "                                       data_format=\"channels_last\",\n",
    "                                       activation=______, \n",
    "                                       input_shape=(28,28,1))) \n",
    "    mymodel.add(keras.layers.Convolution2D(__________,      #<<<< ------ 1\n",
    "                                       (____,___),\n",
    "                                       strides=1,  \n",
    "                                       data_format=\"channels_last\",\n",
    "                                       activation=______)) \n",
    "    mymodel.add(keras.layers.MaxPooling2D(pool_size=(2,2),strides=2,data_format=\"channels_last\")) #get Max over 2D region,and slide\n",
    "    mymodel.add(keras.layers.Flatten())            #reorganize 2DxFilters output into 1D\n",
    "  \n",
    "    #----------------Now add final classification layers\n",
    "    mymodel.add(keras.layers.Dense(32, activation='relu'))   \n",
    "    mymodel.add(keras.layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "    # --------- Now configure model algorithm -----\n",
    "    mymodel.compile(loss='categorical_crossentropy',\n",
    "               optimizer='sgd',       #2   <<<<-------\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "    return mymodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_________' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# call the build model function\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m mymodel \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m     \u001b[38;5;66;03m#<<<---------- set num filters argument here\u001b[39;00m\n\u001b[1;32m      4\u001b[0m mymodel\u001b[38;5;241m.\u001b[39msummary()\n",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m, in \u001b[0;36mbuild_model\u001b[0;34m(numfilters)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_model\u001b[39m(numfilters):   \u001b[38;5;66;03m#<<<---- Hint, use this argument \u001b[39;00m\n\u001b[1;32m      3\u001b[0m     mymodel \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mSequential()\n\u001b[0;32m----> 4\u001b[0m     mymodel\u001b[38;5;241m.\u001b[39madd(keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mConvolution2D(\u001b[43m_________\u001b[49m,      \u001b[38;5;66;03m#<<<< ------ 1\u001b[39;00m\n\u001b[1;32m      5\u001b[0m                                        (___,___),\n\u001b[1;32m      6\u001b[0m                                        strides\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,  \n\u001b[1;32m      7\u001b[0m                                        data_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchannels_last\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m                                        activation\u001b[38;5;241m=\u001b[39m______, \n\u001b[1;32m      9\u001b[0m                                        input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m28\u001b[39m,\u001b[38;5;241m28\u001b[39m,\u001b[38;5;241m1\u001b[39m))) \n\u001b[1;32m     10\u001b[0m     mymodel\u001b[38;5;241m.\u001b[39madd(keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mConvolution2D(__________,      \u001b[38;5;66;03m#<<<< ------ 1\u001b[39;00m\n\u001b[1;32m     11\u001b[0m                                        (____,___),\n\u001b[1;32m     12\u001b[0m                                        strides\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,  \n\u001b[1;32m     13\u001b[0m                                        data_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchannels_last\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     14\u001b[0m                                        activation\u001b[38;5;241m=\u001b[39m______)) \n\u001b[1;32m     15\u001b[0m     mymodel\u001b[38;5;241m.\u001b[39madd(keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mMaxPooling2D(pool_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m),strides\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,data_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchannels_last\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;66;03m#get Max over 2D region,and slide\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name '_________' is not defined"
     ]
    }
   ],
   "source": [
    "# call the build model function\n",
    "mymodel = build_model(numfilters=16)     #<<<---------- set num filters argument here\n",
    "\n",
    "mymodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Fill in parameters for the fit method of the model object\n",
    "\n",
    "View the URL model.fit documentation and fill in the validation data\n",
    "\n",
    "https://keras.io/api/models/model_training_apis/#fit-method\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myES_function = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=5,  restore_best_weights=True) #patience before stopping\n",
    "\n",
    "#------------ Now Run Training\n",
    "fit_history=mymodel.fit(X_train, Y_train, \n",
    "          validation_data=(_____,_______),  #<<<<---- look for the 'test' data defined in the first few cells\n",
    "          batch_size=128, epochs=50, verbose=1,callbacks=[__________])  #<<<--- Look for the early stopping function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The rest of this notebook is plotting and image displays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt      #These provide matlab type of plotting functions\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline                   \n",
    "\n",
    "# list all data in history and print out performance\n",
    "print(fit_history.history.keys())\n",
    "numtraining_epochs=len(fit_history.history['accuracy'])\n",
    "# summarize history for accuracy\n",
    "plt.figure()\n",
    "plt.axis([0 ,numtraining_epochs, 0, 1])\n",
    "plt.plot(fit_history.history['accuracy'])\n",
    "plt.plot(fit_history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val_test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To view a sample image\n",
    "import matplotlib.pyplot as plt      #These provide matlab type of plotting functions\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "tmpimg=np.squeeze(X_train[0,:,:,:]).reshape((28,28))\n",
    "plt.imshow(tmpimg,'gray')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------ GET WEIGHTS From Convolution Layer and make mosaic image \n",
    "Wlist   =mymodel.layers[0].get_weights()      \n",
    "W3D     =np.squeeze(Wlist[0])\n",
    "W3Dchan =W3D.swapaxes(1,2).swapaxes(0,1)  #get the channels as 1st dimension;\n",
    "print(\"W3D shape Wlist[0]:\"+str(W3Dchan.shape))\n",
    "\n",
    "#plot mosaic of filters of \n",
    "ncol =4\n",
    "nrow =np.ceil(16/ncol).astype(int)   #assume 16 is number of filters\n",
    "plt.figure()\n",
    "for i in range(W3Dchan.shape[0]):\n",
    "   plt.subplot(nrow,ncol,i+1)\n",
    "   plt.imshow(W3Dchan[i],'gray')\n",
    "   plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "print('done plotting weights mosaic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ---------------- NOW Visualize the activations for the first training example --------\n",
    "#   1. gather activations from the model layers\n",
    "# -------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "\n",
    "layer_outputs     = [layer.output for layer in mymodel.layers[:]]\n",
    "my_model_actvtns  = keras.models.Model(inputs=mymodel.input, outputs=layer_outputs)\n",
    "x                 = np.expand_dims(X_train[0],0)           #set up a 4D input of 1 image training set \n",
    "my_actvtns_output = my_model_actvtns.predict(x)   #for each image get predictions/activatns\n",
    "\n",
    "print('There are ',str(len(my_actvtns_output))+ ' layers with output activations')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2.  Now output a mosaic of layer 1\n",
    "layeroutput3D      = np.squeeze(my_actvtns_output[0]) #<<---- -try different layer output     \n",
    "ncol =4\n",
    "nrow =np.ceil(16/ncol).astype(int)\n",
    "plt.figure()\n",
    "for i in range(layeroutput3D.shape[2]):  \n",
    "   plt.subplot(nrow,ncol,i+1)\n",
    "   plt.imshow(layeroutput3D[:,:,i],'gray')\n",
    "   plt.axis('off')\n",
    "#plt.savefig(\"test.png\", bbox_inches='tight')\n",
    "plt.show()\n",
    "print('done plotting layer1 activation output mosaic')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
